{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code from /User/waste-classifier/src-tf will be used to train on the v3io:///projects/{{run.project}}/artifacts/images given dataset\n"
     ]
    }
   ],
   "source": [
    "import nuclio\n",
    "from os import environ, path\n",
    "from mlrun import mlconf\n",
    "\n",
    "# Define the `dbpath` - Where our `mlrun-api` services is available\n",
    "# the `http://mlrun-api:8080` is auto-defined by `kubernetes service` definition \n",
    "mlconf.dbpath = mlconf.dbpath or 'http://mlrun-api:8080'\n",
    "\n",
    "# Define the artifact path for the current user's home directory\n",
    "mlconf.artifact_path = mlconf.artifact_path or f'{environ[\"HOME\"]}/artifacts'\n",
    "\n",
    "# # specify paths and artifacts target location\n",
    "code_dir = path.join(path.abspath('./'), 'src-tf') # Where our source code files are saved\n",
    "images_path = path.join(mlconf.artifact_path, 'images') \n",
    "\n",
    "# Specify the project's name for experiment tracking\n",
    "project_name='waste-classifier'\n",
    "\n",
    "print(f'Code from {code_dir} will be used to train on the {images_path} given dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to Download and Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: start-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import json\n",
    "import shutil\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mlrun import DataItem\n",
    " \n",
    "def open_archive(context, \n",
    "                 archive_url: DataItem,\n",
    "                 target_path,\n",
    "                 refresh=False\n",
    "                ):\n",
    "    \"\"\"Open a file/object archive into a target directory\n",
    "    \n",
    "    Currently supports zip and tar.gz\n",
    "    \n",
    "    :param context:      function execution context\n",
    "    :param archive_url:  url of archive file\n",
    "    :param target_path:  file system path to store extracted files\n",
    "    :param key:          key of archive contents in artifact store\n",
    "    :param train_size:    set the train dataset size out of total dataset\n",
    "    \"\"\"\n",
    "    os.makedirs(target_path, exist_ok=True)\n",
    "    \n",
    "    # get the archive as a local file (download if needed)\n",
    "    archive_url = archive_url.local()\n",
    "    \n",
    "    context.logger.info('Extracting zip')\n",
    "    extraction_path = os.path.join(target_path, 'tmp')\n",
    "    zip_ref = zipfile.ZipFile(archive_url, 'r')\n",
    "    zip_ref.extractall(extraction_path)\n",
    "    \n",
    "    \n",
    "    for data_train_test_type in ['TRAIN', 'TEST']:\n",
    "        context.logger.info(f'Processing {data_train_test_type} files')\n",
    "        # get all files paths from `extraction_path`\n",
    "        filenames = [file for file in glob(extraction_path + f'/DATASET/{data_train_test_type}/*/*') if file.endswith('.jpg')]\n",
    "        context.logger.info(f'{len(filenames)} files in {data_train_test_type}')\n",
    "        \n",
    "        # extract labels from filenames by their naming convention (<label>.<number>.jpg)\n",
    "        # and calculate how many images we have per label\n",
    "        context.logger.info('Extracting labels')\n",
    "        _extract_label = lambda filename: os.path.basename(filename).split('_')[0]\n",
    "        file_labels = [_extract_label(file) for file in filenames]\n",
    "        labels, label_counts = np.unique(file_labels, return_counts=True)\n",
    "\n",
    "        # Order the files into a {<label>: [<files list>]} dictionary\n",
    "        context.logger.info('Adding filenames in a dictionary')\n",
    "        files = {label: [] for label in labels}\n",
    "        for label, file in zip(file_labels, filenames):\n",
    "            files[label].append(file)\n",
    "\n",
    "        # create directories for train and test\n",
    "        for label in labels:\n",
    "            _dir = os.path.join(target_path, data_train_test_type, label)\n",
    "            context.logger.info(f'Creating directory {_dir}')\n",
    "            os.makedirs(_dir, exist_ok=True)\n",
    "\n",
    "        # move the files to their appropriate folders (<TRAIN/TEST>/<label>/<file>)\n",
    "        for label, filenames in files.items():\n",
    "            context.logger.info(f'Moving \"{label}\" files in {data_train_test_type}')\n",
    "            for i, file in enumerate(filenames):\n",
    "                shutil.move(file, os.path.join(target_path, data_train_test_type, label, os.path.basename(file)))\n",
    "    shutil.rmtree(extraction_path)\n",
    "\n",
    "    # Add function logging\n",
    "    context.logger.info(f'extracted archive to {target_path}')\n",
    "    context.logger.info(f'Dataset contains the labels {labels}')\n",
    "    \n",
    "    # Log the dataset folder as `content` artifact for later use\n",
    "    context.log_artifact('content', target_path=target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-07-04 18:36:32,374 [info] starting run download uid=191a9e7d3c33407198f3fce5f54b86e6 DB=http://mlrun-api:8080\n",
      "> 2021-07-04 18:36:32,531 [info] Extracting zip\n",
      "> 2021-07-04 18:38:28,565 [info] Processing TRAIN files\n",
      "> 2021-07-04 18:38:28,960 [info] 22564 files in TRAIN\n",
      "> 2021-07-04 18:38:28,961 [info] Extracting labels\n",
      "> 2021-07-04 18:38:28,991 [info] Adding filenames in a dictionary\n",
      "> 2021-07-04 18:38:28,995 [info] Creating directory /v3io/projects/waste-classifier/images/TRAIN/O\n",
      "> 2021-07-04 18:38:29,004 [info] Creating directory /v3io/projects/waste-classifier/images/TRAIN/R\n",
      "> 2021-07-04 18:38:29,007 [info] Moving \"O\" files in TRAIN\n",
      "> 2021-07-04 18:40:21,806 [info] Moving \"R\" files in TRAIN\n",
      "> 2021-07-04 18:41:50,977 [info] Processing TEST files\n",
      "> 2021-07-04 18:41:51,014 [info] 2513 files in TEST\n",
      "> 2021-07-04 18:41:51,015 [info] Extracting labels\n",
      "> 2021-07-04 18:41:51,024 [info] Adding filenames in a dictionary\n",
      "> 2021-07-04 18:41:51,027 [info] Creating directory /v3io/projects/waste-classifier/images/TEST/O\n",
      "> 2021-07-04 18:41:51,035 [info] Creating directory /v3io/projects/waste-classifier/images/TEST/R\n",
      "> 2021-07-04 18:41:51,039 [info] Moving \"O\" files in TEST\n",
      "> 2021-07-04 18:42:03,279 [info] Moving \"R\" files in TEST\n",
      "> 2021-07-04 18:42:13,192 [info] extracted archive to /v3io/projects/waste-classifier/images\n",
      "> 2021-07-04 18:42:13,193 [info] Dataset contains the labels ['O' 'R']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dictlist {\n",
       "  background-color: #4EC64B;\n",
       "  text-align: center;\n",
       "  margin: 4px;\n",
       "  border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;}\n",
       ".artifact {\n",
       "  cursor: pointer;\n",
       "  background-color: #4EC64B;\n",
       "  text-align: left;\n",
       "  margin: 4px; border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;\n",
       "}\n",
       "div.block.hidden {\n",
       "  display: none;\n",
       "}\n",
       ".clickable {\n",
       "  cursor: pointer;\n",
       "}\n",
       ".ellipsis {\n",
       "  display: inline-block;\n",
       "  max-width: 60px;\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "}\n",
       ".master-wrapper {\n",
       "  display: flex;\n",
       "  flex-flow: row nowrap;\n",
       "  justify-content: flex-start;\n",
       "  align-items: stretch;\n",
       "}\n",
       ".master-tbl {\n",
       "  flex: 3\n",
       "}\n",
       ".master-wrapper > div {\n",
       "  margin: 4px;\n",
       "  padding: 10px;\n",
       "}\n",
       "iframe.fileview {\n",
       "  border: 0 none;\n",
       "  height: 100%;\n",
       "  width: 100%;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       ".pane-header-title {\n",
       "  width: 80%;\n",
       "  font-weight: 500;\n",
       "}\n",
       ".pane-header {\n",
       "  line-height: 1;\n",
       "  background-color: #4EC64B;\n",
       "  padding: 3px;\n",
       "}\n",
       ".pane-header .close {\n",
       "  font-size: 20px;\n",
       "  font-weight: 700;\n",
       "  float: right;\n",
       "  margin-top: -5px;\n",
       "}\n",
       ".master-wrapper .right-pane {\n",
       "  border: 1px inset silver;\n",
       "  width: 40%;\n",
       "  min-height: 300px;\n",
       "  flex: 3\n",
       "  min-width: 500px;\n",
       "}\n",
       ".master-wrapper * {\n",
       "  box-sizing: border-box;\n",
       "}\n",
       "</style><script>\n",
       "function copyToClipboard(fld) {\n",
       "    if (document.queryCommandSupported && document.queryCommandSupported('copy')) {\n",
       "        var textarea = document.createElement('textarea');\n",
       "        textarea.textContent = fld.innerHTML;\n",
       "        textarea.style.position = 'fixed';\n",
       "        document.body.appendChild(textarea);\n",
       "        textarea.select();\n",
       "\n",
       "        try {\n",
       "            return document.execCommand('copy'); // Security exception may be thrown by some browsers.\n",
       "        } catch (ex) {\n",
       "\n",
       "        } finally {\n",
       "            document.body.removeChild(textarea);\n",
       "        }\n",
       "    }\n",
       "}\n",
       "function expandPanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName');\n",
       "  console.log(el.title);\n",
       "\n",
       "  document.querySelector(panelName + \"-title\").innerHTML = el.title\n",
       "  iframe = document.querySelector(panelName + \"-body\");\n",
       "\n",
       "  const tblcss = `<style> body { font-family: Arial, Helvetica, sans-serif;}\n",
       "    #csv { margin-bottom: 15px; }\n",
       "    #csv table { border-collapse: collapse;}\n",
       "    #csv table td { padding: 4px 8px; border: 1px solid silver;} </style>`;\n",
       "\n",
       "  function csvToHtmlTable(str) {\n",
       "    return '<div id=\"csv\"><table><tr><td>' +  str.replace(/[\\n\\r]+$/g, '').replace(/[\\n\\r]+/g, '</td></tr><tr><td>')\n",
       "      .replace(/,/g, '</td><td>') + '</td></tr></table></div>';\n",
       "  }\n",
       "\n",
       "  function reqListener () {\n",
       "    if (el.title.endsWith(\".csv\")) {\n",
       "      iframe.setAttribute(\"srcdoc\", tblcss + csvToHtmlTable(this.responseText));\n",
       "    } else {\n",
       "      iframe.setAttribute(\"srcdoc\", this.responseText);\n",
       "    }\n",
       "    console.log(this.responseText);\n",
       "  }\n",
       "\n",
       "  const oReq = new XMLHttpRequest();\n",
       "  oReq.addEventListener(\"load\", reqListener);\n",
       "  oReq.open(\"GET\", el.title);\n",
       "  oReq.send();\n",
       "\n",
       "\n",
       "  //iframe.src = el.title;\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.remove(\"hidden\");\n",
       "  }\n",
       "}\n",
       "function closePanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName')\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (!resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.add(\"hidden\");\n",
       "  }\n",
       "}\n",
       "\n",
       "</script>\n",
       "<div class=\"master-wrapper\">\n",
       "  <div class=\"block master-tbl\"><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>project</th>\n",
       "      <th>uid</th>\n",
       "      <th>iter</th>\n",
       "      <th>start</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>labels</th>\n",
       "      <th>inputs</th>\n",
       "      <th>parameters</th>\n",
       "      <th>results</th>\n",
       "      <th>artifacts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>waste-classifier</td>\n",
       "      <td><div title=\"191a9e7d3c33407198f3fce5f54b86e6\"><a href=\"https://dashboard.default-tenant.app.mlops5.iguazio-c0.com/mlprojects/waste-classifier/jobs/monitor/191a9e7d3c33407198f3fce5f54b86e6/overview\" target=\"_blank\" >...f54b86e6</a></div></td>\n",
       "      <td>0</td>\n",
       "      <td>Jul 04 18:36:32</td>\n",
       "      <td>completed</td>\n",
       "      <td>download</td>\n",
       "      <td><div class=\"dictlist\">v3io_user=daryll-tumambing</div><div class=\"dictlist\">kind=handler</div><div class=\"dictlist\">owner=daryll-tumambing</div><div class=\"dictlist\">host=jupyter-team-c6979bd6-n4vh5</div></td>\n",
       "      <td><div title=\"/v3io/projects/waste-classifier/waste_dataset.zip\">archive_url</div></td>\n",
       "      <td><div class=\"dictlist\">target_path=/v3io/projects/waste-classifier/images</div></td>\n",
       "      <td></td>\n",
       "      <td><div title=\"/v3io/projects/waste-classifier/images\">content</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div></div>\n",
       "  <div id=\"result3cabb473-pane\" class=\"right-pane block hidden\">\n",
       "    <div class=\"pane-header\">\n",
       "      <span id=\"result3cabb473-title\" class=\"pane-header-title\">Title</span>\n",
       "      <span onclick=\"closePanel(this)\" paneName=\"result3cabb473\" class=\"close clickable\">&times;</span>\n",
       "    </div>\n",
       "    <iframe class=\"fileview\" id=\"result3cabb473-body\"></iframe>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to track results use .show() or .logs() or in CLI: \n",
      "!mlrun get run 191a9e7d3c33407198f3fce5f54b86e6 --project waste-classifier , !mlrun logs 191a9e7d3c33407198f3fce5f54b86e6 --project waste-classifier\n",
      "> 2021-07-04 18:42:13,429 [info] run executed, status=completed\n"
     ]
    }
   ],
   "source": [
    "# download images from s3 using the local `open_archive` function\n",
    "from mlrun import NewTask, run_local\n",
    "import os\n",
    "\n",
    "# Set the source-data URL\n",
    "url_prefix = os.environ.get('DATA_SOURCE_URL_PREFIX', '/v3io/projects/waste-classifier/')\n",
    "\n",
    "open_archive_task = NewTask(name='download', \n",
    "                            handler=open_archive, \n",
    "                            params={'target_path': f'{url_prefix.rstrip(\"/\")}/images'},\n",
    "                            inputs={'archive_url': f'{url_prefix.rstrip(\"/\")}/waste_dataset.zip'})\n",
    "\n",
    "\n",
    "download_run = run_local(open_archive_task, \n",
    "                         project=project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import new_project, code_to_function\n",
    "project_dir = './'\n",
    "hvdproj = new_project(project_name, project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils = code_to_function(kind='job', \n",
    "                         name='utils',\n",
    "                         image='mlrun/mlrun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.kubejob.KubejobRuntime at 0x7f46ae52e350>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hvdproj.set_function(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/User/waste-classifier/src-tf/horovod-training.py\n"
     ]
    }
   ],
   "source": [
    "HOROVOD_FILE = os.path.join(code_dir, 'horovod-training.py')\n",
    "print(HOROVOD_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.mpijob.v1.MpiRuntimeV1 at 0x7f46acf92610>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlrun import new_function\n",
    "import os\n",
    "\n",
    "# Set `use_gpu` to True to run the function using a GPU Configuration\n",
    "use_gpu = False\n",
    "use_gpu = True\n",
    "\n",
    "image = lambda gpu: 'mlrun/ml-models-gpu' if gpu else 'mlrun/ml-models' \n",
    "\n",
    "# Set basic function parameters\n",
    "trainer = new_function(name='trainer',\n",
    "                       kind='mpijob',\n",
    "                       command=HOROVOD_FILE)\n",
    "trainer.spec.replicas = 2\n",
    "\n",
    "# Set a minimal number of dedicated CPUs per node\n",
    "trainer.with_requests(cpu=4)\n",
    "\n",
    "# Pick image by wanted TF version\n",
    "trainer.spec.image = image(use_gpu)\n",
    "    \n",
    "# Add GPUs to workers?\n",
    "if use_gpu:\n",
    "    trainer.gpus(1)\n",
    "\n",
    "# Registre the function to the project\n",
    "hvdproj.set_function(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.function.RemoteRuntime at 0x7f46bb4ef510>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hvdproj.set_function('hub://tf2_serving', 'serving')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.artifacts.base.Artifact at 0x7f46acf92ad0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hvdproj.log_artifact(\n",
    "    'images', \n",
    "    target_path=f'{url_prefix}waste_dataset.zip',\n",
    "    artifact_path=mlconf.artifact_path)\n",
    "#print(hvdproj.to_yaml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting workflow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile workflow.py\n",
    "from kfp import dsl\n",
    "from mlrun import mount_v3io\n",
    "\n",
    "funcs = {}\n",
    "\n",
    "\n",
    "def init_functions(functions: dict, project=None, secrets=None):\n",
    "    '''\n",
    "    This function will run before running the project.\n",
    "    It allows us to add our specific system configurations to the functions\n",
    "    like mounts or secrets if needed.\n",
    "\n",
    "    In this case we will add Iguazio's user mount to our functions using the\n",
    "    `mount_v3io()` function to automatically set the mount with the needed\n",
    "    variables taken from the environment. \n",
    "    * mount_v3io can be replaced with mlrun.platforms.mount_pvc() for \n",
    "    non-iguazio mount\n",
    "\n",
    "    @param functions: <function_name: function_yaml> dict of functions in the\n",
    "                        workflow\n",
    "    @param project: project object\n",
    "    @param secrets: secrets required for the functions for s3 connections and\n",
    "                    such\n",
    "    '''\n",
    "    for f in functions.values():\n",
    "        f.apply(mount_v3io())                  # On Iguazio (Auto-mount /User)\n",
    "        # f.apply(mlrun.platforms.mount_pvc()) # Non-Iguazio mount\n",
    "        \n",
    "    functions['serving'].set_env('MODEL_CLASS', 'TFModel')\n",
    "    functions['serving'].set_env('IMAGE_HEIGHT', '224')\n",
    "    functions['serving'].set_env('IMAGE_WIDTH', '224')\n",
    "    functions['serving'].set_env('ENABLE_EXPLAINER', 'False')\n",
    "    functions['serving'].spec.min_replicas = 1\n",
    "\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name='Image classification demo',\n",
    "    description='Train an Image Classification TF Algorithm using MLRun on Waste Dataset'\n",
    ")\n",
    "def kfpipeline(\n",
    "        image_archive='store:///images',\n",
    "        images_dir='/User/artifacts/images',\n",
    "        checkpoints_dir='/User/artifacts/models/checkpoints',\n",
    "        model_name='waste_classifier',\n",
    "        epochs: int=2):\n",
    "\n",
    "    # step 1: download and prep images\n",
    "    open_archive = funcs['utils'].as_step(name='download',\n",
    "                                          handler='open_archive',\n",
    "                                          params={'target_path': images_dir},\n",
    "                                          inputs={'archive_url': image_archive},\n",
    "                                          outputs=['content'])\n",
    "\n",
    "    # step 2: train the model\n",
    "    train_dir = str(open_archive.outputs['content']) + '/TRAIN'\n",
    "    val_dir = str(open_archive.outputs['content']) + '/TEST'\n",
    "    train = funcs['trainer'].as_step(name='train',\n",
    "                                     params={'epochs': epochs,\n",
    "                                             'checkpoints_dir': checkpoints_dir,\n",
    "                                             'model_dir'     : 'tfmodels',\n",
    "                                             'train_path'     : train_dir,\n",
    "                                             'val_path'       : val_dir,\n",
    "                                             'batch_size'     : 32},\n",
    "                                     outputs=['model'])\n",
    "\n",
    "    # deploy the model using nuclio functions\n",
    "    deploy = funcs['serving'].deploy_step(models={model_name: train.outputs['model']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hvdproj.set_workflow('main', 'workflow.py', embed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hvdproj.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-07-04 10:34:23,917 [info] using in-cluster config.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"https://dashboard.default-tenant.app.mlops5.iguazio-c0.com/pipelines/#/experiments/details/a30989d4-abc9-4999-bd87-83eed3b1f28b\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"https://dashboard.default-tenant.app.mlops5.iguazio-c0.com/pipelines/#/runs/details/9757ea6a-637c-4f9c-b412-950762d55e93\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-07-04 10:34:24,390 [info] Pipeline run id=9757ea6a-637c-4f9c-b412-950762d55e93, check UI or DB for progress\n",
      "> 2021-07-04 10:34:24,391 [info] waiting for pipeline run completion\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'gcloud': 'gcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a20ea8459810>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                'images_dir': artifact_path + '/images'}, \n\u001b[1;32m      6\u001b[0m     \u001b[0martifact_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0martifact_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     dirty=True, watch=True)\n\u001b[0m",
      "\u001b[0;32m~/.pythonlibs/jupyter-team/lib/python3.7/site-packages/mlrun/projects/project.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, name, workflow_path, arguments, artifact_path, namespace, sync, watch, dirty, ttl)\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkflow_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_run_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnotifiers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRunNotifications\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_slack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pythonlibs/jupyter-team/lib/python3.7/site-packages/mlrun/projects/project.py\u001b[0m in \u001b[0;36mget_run_status\u001b[0;34m(self, workflow_id, timeout, expected_statuses, notifiers)\u001b[0m\n\u001b[1;32m   1365\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"waiting for pipeline run completion\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             run_info = wait_for_pipeline_completion(\n\u001b[0;32m-> 1367\u001b[0;31m                 \u001b[0mworkflow_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpected_statuses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m             )\n\u001b[1;32m   1369\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrun_info\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pythonlibs/jupyter-team/lib/python3.7/site-packages/mlrun/run.py\u001b[0m in \u001b[0;36mwait_for_pipeline_completion\u001b[0;34m(run_id, timeout, expected_statuses, namespace)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m         \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_run_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/lib/python3.7/site-packages/kfp/_client.py\u001b[0m in \u001b[0;36mwait_for_run_completion\u001b[0;34m(self, run_id, timeout)\u001b[0m\n\u001b[1;32m    688\u001b[0m       if (datetime.datetime.now() - last_token_refresh_time\n\u001b[1;32m    689\u001b[0m           > _GCP_ACCESS_TOKEN_TIMEOUT):\n\u001b[0;32m--> 690\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_refresh_api_client_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0mlast_token_refresh_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/lib/python3.7/site-packages/kfp/_client.py\u001b[0m in \u001b[0;36m_refresh_api_client_token\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m       \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m     \u001b[0mnew_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_gcp_access_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_existing_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'authorization'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/lib/python3.7/site-packages/kfp/_auth.py\u001b[0m in \u001b[0;36mget_gcp_access_token\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m       \u001b[0;31m# Casting to string to accommodate API server request schema.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m       \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Failed to get GCP access token: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[0;32m--> 411\u001b[0;31m                **kwargs).stdout\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stderr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    798\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;31m# Cleanup if the child failed starting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1549\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0merrno_num\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'gcloud': 'gcloud'"
     ]
    }
   ],
   "source": [
    "artifact_path = path.abspath('./pipe/{{workflow.uid}}')\n",
    "run_id = hvdproj.run(\n",
    "    'main',\n",
    "    arguments={'model_name': 'waste_classifier',\n",
    "               'images_dir': artifact_path + '/images'}, \n",
    "    artifact_path=artifact_path, \n",
    "    dirty=True, watch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serving Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test image to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'url_prefix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-86f47b57fa41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Testing event\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0morganic_image_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{url_prefix}images/TEST/O/O_12568.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'http'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0morganic_image_url\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morganic_image_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'url_prefix' is not defined"
     ]
    }
   ],
   "source": [
    "# Testing event\n",
    "organic_image_url = f'{url_prefix}images/TEST/O/O_12568.jpg'\n",
    "\n",
    "if 'http' in organic_image_url:\n",
    "    response = requests.get(organic_image_url)\n",
    "    organic_image = response.content\n",
    "    img = Image.open(BytesIO(organic_image))\n",
    "else:\n",
    "    organic_image = open(organic_image_url,'rb').read()\n",
    "    img = Image.open(organic_image_url)\n",
    "\n",
    "print('Test image:')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'url_prefix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-ee109beba467>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Testing event\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrecyclable_image_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{url_prefix}images/TEST/R/R_10001.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'http'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrecyclable_image_url\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecyclable_image_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'url_prefix' is not defined"
     ]
    }
   ],
   "source": [
    "# Testing event\n",
    "recyclable_image_url = f'{url_prefix}images/TEST/R/R_10001.jpg'\n",
    "\n",
    "if 'http' in recyclable_image_url:\n",
    "    response = requests.get(recyclable_image_url)\n",
    "    recyclable_image = response.content\n",
    "    img = Image.open(BytesIO(recyclable_image_url))\n",
    "else:\n",
    "    recyclable_image = open(recyclable_image_url,'rb').read()\n",
    "    img = Image.open(recyclable_image)\n",
    "\n",
    "print('Test image:')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send image to endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://nuclio-waste-classifier-tf2-serving:8080\n"
     ]
    }
   ],
   "source": [
    "addr = 'http://nuclio-{}-{}:8080'.format(hvdproj.name, hvdproj.func('serving').metadata.name)\n",
    "print(addr)\n",
    "headers = {'Content-type': 'image/jpeg'}\n",
    "url = addr + f'/waste_classifier/predict'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Organic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception caught in handler - \"received: {'instances': [<_io.BytesIO object at 0x7f907b71de90>], 'content_type': 'image/jpeg'}\": Traceback (most recent call last):\n",
      "  File \"/opt/nuclio/tf2_serving.py\", line 43, in preprocess\n",
      "    img = Image.open(byte_image)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/PIL/Image.py\", line 2968, in open\n",
      "    \"cannot identify image file %r\" % (filename if filename else fp)\n",
      "PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f907b71de90>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/nuclio/_nuclio_wrapper.py\", line 114, in serve_requests\n",
      "    self._handle_event(event)\n",
      "  File \"/opt/nuclio/_nuclio_wrapper.py\", line 262, in _handle_event\n",
      "    entrypoint_output = self._entrypoint(self._context, event)\n",
      "  File \"/opt/nuclio/tf2_serving.py\", line 80, in handler\n",
      "    return context.mlrun_handler(context, event)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/mlrun/serving/v1_serving.py\", line 179, in nuclio_serving_handler\n",
      "    return route(context, model_name, event)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/mlrun/serving/v1_serving.py\", line 311, in post\n",
      "    request = model.preprocess(body)\n",
      "  File \"/opt/nuclio/tf2_serving.py\", line 53, in preprocess\n",
      "    raise Exception(f'received: {body}')\n",
      "Exception: received: {'instances': [<_io.BytesIO object at 0x7f907b71de90>], 'content_type': 'image/jpeg'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(url=url, \n",
    "                         data=json.dumps({'data_url': organic_image_url}), \n",
    "                         headers=headers)\n",
    "print(response.content.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.9 ms ± 5.11 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "requests.post(url=url, \n",
    "              data=json.dumps({'data_url': organic_image_url}), \n",
    "              headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0]\n"
     ]
    }
   ],
   "source": [
    "headers = {'Content-type': 'image/jpeg'}\n",
    "response = requests.post(url=url, \n",
    "                         data=organic_image, \n",
    "                         headers=headers)\n",
    "print(response.content.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.03 s ± 53.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "requests.post(url=url, \n",
    "              data=organic_image, \n",
    "              headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Recyclable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception caught in handler - \"received: {'instances': [<_io.BytesIO object at 0x7fcb526bcfb0>], 'content_type': 'image/jpeg'}\": Traceback (most recent call last):\n",
      "  File \"/opt/nuclio/tf2_serving.py\", line 43, in preprocess\n",
      "    img = Image.open(byte_image)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/PIL/Image.py\", line 2968, in open\n",
      "    \"cannot identify image file %r\" % (filename if filename else fp)\n",
      "PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fcb526bcfb0>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/nuclio/_nuclio_wrapper.py\", line 114, in serve_requests\n",
      "    self._handle_event(event)\n",
      "  File \"/opt/nuclio/_nuclio_wrapper.py\", line 262, in _handle_event\n",
      "    entrypoint_output = self._entrypoint(self._context, event)\n",
      "  File \"/opt/nuclio/tf2_serving.py\", line 80, in handler\n",
      "    return context.mlrun_handler(context, event)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/mlrun/serving/v1_serving.py\", line 179, in nuclio_serving_handler\n",
      "    return route(context, model_name, event)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/mlrun/serving/v1_serving.py\", line 311, in post\n",
      "    request = model.preprocess(body)\n",
      "  File \"/opt/nuclio/tf2_serving.py\", line 53, in preprocess\n",
      "    raise Exception(f'received: {body}')\n",
      "Exception: received: {'instances': [<_io.BytesIO object at 0x7fcb526bcfb0>], 'content_type': 'image/jpeg'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(url=url, \n",
    "                         data=json.dumps({'data_url': recyclable_image_url}), \n",
    "                         headers=headers)\n",
    "print(response.content.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.07 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "16.3 ms ± 9.43 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "requests.post(url=url, \n",
    "              data=json.dumps({'data_url': recyclable_image_url}), \n",
    "              headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0]\n"
     ]
    }
   ],
   "source": [
    "headers = {'Content-type': 'image/jpeg'}\n",
    "response = requests.post(url=url, \n",
    "                         data=recyclable_image, \n",
    "                         headers=headers)\n",
    "print(response.content.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "991 ms ± 10.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "requests.post(url=url, \n",
    "              data=recyclable_image, \n",
    "              headers=headers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
