kind: project
metadata:
  name: waste-classifier
spec:
  functions:
  - name: utils
    spec:
      kind: job
      metadata:
        name: utils
        tag: ''
        project: waste-classifier
      spec:
        command: ''
        args: []
        image: mlrun/mlrun
        env: []
        default_handler: ''
        entry_points:
          open_archive:
            name: open_archive
            doc: 'Open a file/object archive into a target directory


              Currently supports zip and tar.gz'
            parameters:
            - name: context
              doc: function execution context
              default: ''
            - name: archive_url
              type: DataItem
              doc: url of archive file
              default: ''
            - name: target_path
              doc: file system path to store extracted files
              default: ''
            - name: refresh
              default: false
            outputs:
            - default: ''
            lineno: 12
        description: ''
        build:
          functionSourceCode: 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
          commands: []
          code_origin: utils.ipynb
        affinity: null
      verbose: false
  - name: trainer
    spec:
      kind: mpijob
      metadata:
        name: trainer
        project: waste-classifier
        categories: []
      spec:
        command: /User/waste-classifier/src-tf/horovod-training.py
        args: []
        image: mlrun/ml-models
        env: []
        resources:
          requests:
            cpu: 4
        description: ''
        replicas: 2
        build:
          commands: []
        mpi_args:
        - -x
        - NCCL_SOCKET_NTHREADS=2
        - -x
        - NCCL_NSOCKS_PERTHREAD=8
        - -x
        - NCCL_MIN_NCHANNELS=4
        clean_pod_policy: All
        affinity: null
      verbose: false
  - url: hub://tf2_serving
    name: serving
  workflows:
  - name: main
    code: "from kfp import dsl\nfrom mlrun import mount_v3io\n\nfuncs = {}\n\n\ndef\
      \ init_functions(functions: dict, project=None, secrets=None):\n    '''\n  \
      \  This function will run before running the project.\n    It allows us to add\
      \ our specific system configurations to the functions\n    like mounts or secrets\
      \ if needed.\n\n    In this case we will add Iguazio's user mount to our functions\
      \ using the\n    `mount_v3io()` function to automatically set the mount with\
      \ the needed\n    variables taken from the environment. \n    * mount_v3io can\
      \ be replaced with mlrun.platforms.mount_pvc() for \n    non-iguazio mount\n\
      \n    @param functions: <function_name: function_yaml> dict of functions in\
      \ the\n                        workflow\n    @param project: project object\n\
      \    @param secrets: secrets required for the functions for s3 connections and\n\
      \                    such\n    '''\n    for f in functions.values():\n     \
      \   f.apply(mount_v3io())                  # On Iguazio (Auto-mount /User)\n\
      \        # f.apply(mlrun.platforms.mount_pvc()) # Non-Iguazio mount\n      \
      \  \n    functions['serving'].set_env('MODEL_CLASS', 'TFModel')\n    functions['serving'].set_env('IMAGE_HEIGHT',\
      \ '224')\n    functions['serving'].set_env('IMAGE_WIDTH', '224')\n    functions['serving'].set_env('ENABLE_EXPLAINER',\
      \ 'False')\n    functions['serving'].spec.min_replicas = 1\n\n\n@dsl.pipeline(\n\
      \    name='Image classification demo',\n    description='Train an Image Classification\
      \ TF Algorithm using MLRun on Waste Dataset'\n)\ndef kfpipeline(\n        image_archive='store:///images',\n\
      \        images_dir='/User/artifacts/images',\n        checkpoints_dir='/User/artifacts/models/checkpoints',\n\
      \        model_name='waste_classifier',\n        epochs: int=2):\n\n    # step\
      \ 1: download and prep images\n    open_archive = funcs['utils'].as_step(name='download',\n\
      \                                          handler='open_archive',\n       \
      \                                   params={'target_path': images_dir},\n  \
      \                                        inputs={'archive_url': image_archive},\n\
      \                                          outputs=['content'])\n\n    # step\
      \ 2: train the model\n    train_dir = str(open_archive.outputs['content']) +\
      \ '/TRAIN'\n    val_dir = str(open_archive.outputs['content']) + '/TEST'\n \
      \   train = funcs['trainer'].as_step(name='train',\n                       \
      \              params={'epochs': epochs,\n                                 \
      \            'checkpoints_dir': checkpoints_dir,\n                         \
      \                    'model_dir'     : 'tfmodels',\n                       \
      \                      'train_path'     : train_dir,\n                     \
      \                        'val_path'       : val_dir,\n                     \
      \                        'batch_size'     : 32},\n                         \
      \            outputs=['model'])\n\n    # deploy the model using nuclio functions\n\
      \    deploy = funcs['serving'].deploy_step(models={model_name: train.outputs['model']})\n"
  artifacts:
  - key: images
    kind: ''
    iter: 0
    tree: latest
    target_path: /User/waste-classifier/waste_dataset.zip
    db_key: images
  artifact_path: v3io:///projects/{{run.project}}/artifacts
  source: ''
  subpath: ''
  origin_url: ''
  desired_state: online
